<div class="github-widget" data-repo="seriousran/awesome-qa"></div>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-6890694312814945" data-ad-slot="5473692530" data-ad-format="auto"  data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
## Awesome Question Answering [![Awesome](https://awesome.re/badge.svg)](https://github.com/sindresorhus/awesome) 

_精选的清单 __[Question Answering (QA)](https://en.wikipedia.org/wiki/Question_answering)__这是信息检索和自然语言处理（NLP）领域中的计算机科学学科，致力于使用机器学习和深度学习_

_从自然语言处理到机器学习到深度学习的信息搜索和问答环节<br/>
_问答系统主题的精选列表，是信息检索和自然语言处理领域的计算机科学学科 - 使用机器学习和深度学习_


<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->


<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## Recent Trends
### Recent QA Models
-UnifiedQA：使用单个QA系统跨越格式边界（2020）
  -演示：https：//unifiedqa.apps.allenai.org/
 ProQA：一种资源有效的方法，用于为开放域QA和IR预先训练密集的语料库索引.  （2020年）
  -论文：https：//arxiv.org/pdf/2005.00038.pdf
  -github：https：//github.com/xwhan/ProQA
-TYDI质量检查：使用类型多样的语言寻求信息的问题解答基准（2020）
  -论文：https：//arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf
-回顾阅读器，用于机器阅读理解
  -论文：https：//arxiv.org/pdf/2001.09694v2.pdf
-TANDA：转移和调整预训练变压器模型以用于答案句子选择（AAAI 2020）
  -论文：https：//arxiv.org/pdf/1911.04118.pdf
### Recent Language Models
- [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB)，凯文·克拉克（Kevin Clark）等人，ICLR，2020年.
- [TinyBERT: Distilling BERT for Natural Language Understanding](https://openreview.net/pdf?id=rJx0Q6EFPB), Xiaoqi Jiao, et al., ICLR, 2020.
- [MINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers](https://arxiv.org/abs/2002.10957), Wenhui Wang, et al., arXiv, 2020.
- [T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)，Colin Raffel等人，arXiv预印本，2019年.
- [ERNIE: Enhanced Language Representation with Informative Entities](https://arxiv.org/abs/1905.07129), Zhengyan Zhang, et al., ACL, 2019.
- [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)，Yang Zhilin Yang等人，arXiv预印本，2019.
- [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942), Zhenzhong Lan, et al., arXiv preprint, 2019.
- [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692), Yinhan Liu, et al., arXiv preprint, 2019.
- [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/pdf/1910.01108.pdf)，Victor sinh等人，ArXiv，2019年.
- [SpanBERT: Improving Pre-training by Representing and Predicting Spans](https://arxiv.org/pdf/1907.10529v3.pdf)，Mandar Joshi等人，TACL，2019年.
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)，Jacob Devlin等人，NAACL 2019，2018年.
### AAAI 2020
  - [TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection](https://arxiv.org/pdf/1911.04118.pdf)，Siddhant Garg等人，AAAI 2020，2019年11月.
### ACL 2019
  -[MEDIQA 2019文本推理共享任务概述，
问题包含和问题回答]（https://www.aclweb.org/anthology/W19-5039），Asma Ben Abacha等人，ACL-W 2019，2019年8月.
  - [Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications](https://arxiv.org/pdf/1906.02829v1.pdf), Wei Zhao, et al., ACL 2019, Jun 2019.
  - [Cognitive Graph for Multi-Hop Reading Comprehension at Scale](https://arxiv.org/pdf/1905.05460v2.pdf), Ming Ding, et al., ACL 2019, Jun 2019.
  - [Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index](https://arxiv.org/abs/1906.05807)，Minjoon Seo等人，ACL 2019，2019年6月.
  - [Unsupervised Question Answering by Cloze Translation](https://arxiv.org/abs/1906.04980)，Patrick Lewis等人，ACL 2019，2019年6月.
  - [SemEval-2019 Task 10: Math Question Answering](https://www.aclweb.org/anthology/S19-2153)，Mark Hopkins等人，ACL-W 2019，2019年6月.
  - [Improving Question Answering over Incomplete KBs with Knowledge-Aware Reader](https://arxiv.org/abs/1905.07098), Wenhan Xiong, et al., ACL 2019, May 2019.
  - [Matching Article Pairs with Graphical Decomposition and Convolutions](https://arxiv.org/pdf/1802.07459v2.pdf)，Bang Liu等人，ACL 2019,2019年5月.
  - [Episodic Memory Reader: Learning what to Remember for Question Answering from Streaming Data](https://arxiv.org/abs/1903.06164)，Moonsu Han等人，ACL 2019，2019年3月.
  - [Natural Questions: a Benchmark for Question Answering Research](https://ai.google/research/pubs/pub47761)，Tom Kwiatkowski等，TACL 2019,2019年1月.
  - [Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension](https://arxiv.org/abs/1811.00232)，Daesik Kim等人，ACL 2019，2018年11月.
### EMNLP-IJCNLP 2019
  - [Language Models as Knowledge Bases?](https://arxiv.org/pdf/1909.01066v2.pdf)Fabio Perron等人，EMNLP-IJCNLP 2019,2019年5月.
  - [LXMERT: Learning Cross-Modality Encoder Representations from Transformers](https://arxiv.org/pdf/1908.07490v3.pdf), Hao Tan, et al., EMNLP-IJCNLP 2019, Dec 2019.
  - [Answering Complex Open-domain Questions Through Iterative Query Generation](https://arxiv.org/pdf/1910.07000v1.pdf), Peng Qi, et al., EMNLP-IJCNLP 2019, Oct 2019.
  - [KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning](https://arxiv.org/pdf/1909.02151v1.pdf), Bill Yuchen Lin, et al., EMNLP-IJCNLP 2019, Sep 2019.
  - [Mixture Content Selection for Diverse Sequence Generation](https://arxiv.org/pdf/1909.01953v1.pdf)，Jaemin Cho等人，EMNLP-IJCNLP 2019，2019年9月.
  - [A Discrete Hard EM Approach for Weakly Supervised Question Answering](https://arxiv.org/pdf/1909.04849v1.pdf)，Sewon Min等人，EMNLP-IJCNLP，2019年9月，2019年.
### Arxiv
  - [Investigating the Successes and Failures of BERT for Passage Re-Ranking](https://arxiv.org/abs/1905.01758)，Harshith Padigela等人，ArXiv预印本，2019年5月.
  - [BERT with History Answer Embedding for Conversational Question Answering](https://arxiv.org/abs/1905.05412)，Chen Qu等人，arXiv预印本，2019年5月.
  - [Understanding the Behaviors of BERT in Ranking](https://arxiv.org/abs/1904.07531), Yifan Qiao, et al., arXiv preprint, Apr 2019.
  - [BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis](https://arxiv.org/abs/1904.02232)，Hu Xu等人，ArXiv预印本，2019年4月.
  - [End-to-End Open-Domain Question Answering with BERTserini](https://arxiv.org/abs/1902.01718), Wei Yang, et al., arXiv preprint, Feb 2019.
  - [A BERT Baseline for the Natural Questions](https://arxiv.org/abs/1901.08634)克里斯·阿尔贝蒂（Chris Alberti）等人，ArXiv预印本，2019年1月.
  - [Passage Re-ranking with BERT](https://arxiv.org/abs/1901.04085)，Rodrigo Nogueira等人，ArXiv预印本，2019年1月.
  - [SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering](https://arxiv.org/abs/1812.03593), Chenguang Zhu, et al., arXiv, Dec 2018.
### Dataset
  - [ELI5: Long Form Question Answering](https://arxiv.org/abs/1907.09190)，安吉拉·范（Angela Fan）等人，ACL 2019，2019年7月
  -[CODAH：具有对抗性的问答数据集，用于
常识]（https://www.aclweb.org/anthology/W19-2008.pdf），Michael Chen等，RepEval 2019，Jun 2019.
  
## About QA
### Types of QA
-单次质量检查：在不考虑任何上下文的情况下进行回答
-会话质量检查：使用预先的会话轮流
#### Subtypes of QA
-基于知识的质量检查
-基于表格/列表的质量检查
-基于文本的质量检查
-基于社区的质量检查
-视觉质量检查

### Analysis and Parsing for Pre-processing in QA systems
语言分析
  1. [Morphological analysis](https://www.cs.bham.ac.uk/~pjh/sem1a5/pt2/pt2_intro_morphology.html)
  2. [Named Entity Recognition(NER)](https://github.com/seriousran/awesome-qa/blob/master/mds/named-entity-recognition.md)
  3.同名/多义分析
  4.语法解析（Dependency Parsing）
  5.语义识别

### Most QA systems have roughly 3 parts
1.事实提取<br/>
    1.实体提取<br/>
        1. [Named-Entity Recognition(NER)](https://github.com/seriousran/awesome-qa/blob/master/mds/named-entity-recognition.md)
    2. [Relation Extraction](https://github.com/seriousran/awesome-qa/blob/master/mds/relation-extraction.md) <br/>
2.了解问题
3.产生答案

## Events
-Wolfram Alpha在2009年推出了答案引擎.
-IBM Watson系统击败了顶尖*[Jeopardy!](https://www.jeopardy.com)* 2011年冠军.
-苹果的Siri于2011年集成了Wolfram Alpha的应答引擎.
-Google通过在2012年利用免费的基础知识库推出了“知识图谱”，从而接受了质量检查.
 -亚马逊回声|  Alexa（2015），Google主页|  Google助手（2016年），INVOKE |  MS Cortana（2017），HomePod（2017）

## Systems
- [IBM Watson](https://www.ibm.com/watson/) -具有最先进的性能. 
- [Facebook DrQA](https://research.fb.com/downloads/drqa/)  -应用于SQuAD1.0数据集.  SQuAD2.0数据集已发布.  但是DrQA尚未经过测试.
- [MIT media lab's Knowledge graph](http://conceptnet.io/) -是免费提供的语义网络，旨在帮助计算机理解人们使用的单词的含义.

## Competitions in QA

 |  |  数据集  语言|  主办单位|  由于  最高排名|  型号|  现状  超越人类绩效
|---|------------------|---------------|---------------------|-------|-------------------------|-------------------------|--------|------------------------|
| 0 | [Story Cloze Test](http://cs.rochester.edu/~nasrinm/files/Papers/lsdsem17-shared-task.pdf)  |  英文|  大学  罗切斯特  2016 |  msap |  逻辑回归|  已关闭  x |
| 1 | MS MARCO         | English       | Microsoft           | 2016  | YUANFUDAO research NLP  | MARS                    | Closed | o                      |
 |  2 |  MS MARCO V2 |  英文|  微软|  2018 |  NTT Media Intelli.  实验室  |  面具问与答风格|  开了  x |
| 3 | [SQuAD](https://arxiv.org/abs/1606.05250)             |  英文|  大学  斯坦福大学|  2018 |  XLNet（单个模型）| XLNet团队|  已关闭  o |
| 4 | [SQuAD 2.0](https://rajpurkar.github.io/SQuAD-explorer/)         |  英文|  大学  斯坦福大学|  2018 |  PINGAN全能型|  ALBERT + DAAF +验证程序（集成）|  开了  o |
| 5 | [TriviaQA](http://nlp.cs.washington.edu/triviaqa/)         | English       | Univ. of Washington | 2017  | Ming Yan                | -                       | Closed | -                      |
| 6 | [decaNLP](https://decanlp.com/)           |  英文|  Salesforce研究|  2018 |  Salesforce研究|  MQAN |  已关闭  x |
| 7 | [DuReader Ver1.](https://ai.baidu.com/broad/introduction)           |  中文|  百度|  2015 |  |  T型阅读器（单）|  已关闭  x |
| 8 | [DuReader Ver2.](https://ai.baidu.com/broad/introduction)           |  中文|  百度|  2017 |  文艺复兴|  AliReader |  开了  -|
| 9 | [KorQuAD](https://korquad.github.io/KorQuad%201.0/)     |  韩语|  LG CNS AI研究|  2018 |  Clova AI LaRva团队|  LaRva-Kor-Large + + CLaF（单个）|  已关闭  o |
| 10 | [KorQuAD 2.0](https://korquad.github.io/)     |  韩语|  LG CNS AI研究|  2019 |  江原大学  KNU基线（单个模型）|  开了  x |
| 11 | [CoQA](https://stanfordnlp.github.io/coqa/)     |  英文|  大学  斯坦福大学|  2018 |  追益科技|  RoBERTa + AT + KD（集成）|  开了  o |

## Publications
-论文
  - ["Learning to Skim Text"](https://arxiv.org/pdf/1704.06877.pdf), Adams Wei Yu, Hongrae Lee, Quoc V. Le, 2017.
    ：仅在文本中显示您想要的内容
  - ["Deep Joint Entity Disambiguation with Local Neural Attention"](https://arxiv.org/pdf/1704.04920.pdf)，Octavian-Eugen Ganea和Thomas Hofmann，2017年.
  - ["BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION"](https://arxiv.org/pdf/1611.01603.pdf)，Minjoon Seo，Aniruddha Kembhavi，Ali Farhadi，Hananneh Hajishirzi，ICLR，2017年.
  - ["Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks"](http://nlp.cs.berkeley.edu/pubs/FrancisLandau-Durrett-Klein_2016_EntityConvnets_paper.pdf)，Matthew Francis-Landau，Greg Durrett和Dan Klei，NAACL-HLT，2016年.
    - https://GitHub.com/matthewfl/nlp-entity-convnet
  - ["Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions"](https://ieeexplore.ieee.org/document/6823700/), Wei Shen, Jianyong Wang, Jiawei Han, IEEE Transactions on Knowledge and Data Engineering(TKDE), 2014.
  - ["Introduction to “This is Watson"](https://ieeexplore.ieee.org/document/6177724/)，IBM研究与开发杂志，DA Ferrucci，2012年.
  - ["A survey on question answering technology from an information retrieval perspective"](https://www.sciencedirect.com/science/article/pii/S0020025511003860)，信息科学，2011年.
  - ["Question Answering in Restricted Domains: An Overview"](https://www.mitpressjournals.org/doi/abs/10.1162/coli.2007.33.1.41)，迭戈·莫拉（DiegoMollá）和何塞·路易斯·维斯多（JoséLuis Vicedo），计算语言学，2007年
  -[“自然语言问答：从这里观看”]（），L Hirschman，R Gaizauskas，自然语言工程，2001年.
  -实体消歧/实体链接

## Codes
- [BiDAF](https://github.com/allenai/bi-att-flow) -双向注意力流（BIDAF）网络是一个多阶段的分层过程，它以不同的粒度级别表示上下文，并使用双向注意力流机制来获取查询感知的上下文表示，而无需进行早期汇总. 
   -官方；  Tensorflow v1.2
  - [Paper](https://arxiv.org/pdf/1611.01603.pdf)
- [QANet](https://github.com/NLPLearn/QANet) -Q＆A体系结构不需要循环网络：其编码器仅包含卷积和自我注意，其中卷积模型化了本地交互，而自我注意模型化了全局交互.
   - 谷歌;  非官方;  Tensorflow v1.5
- [R-Net](https://github.com/HKUST-KnowComp/R-Net) -用于理解理解式问题回答的端到端神经网络模型，旨在回答给定段落中的问题.
   - 多发性硬化症;  科大非正式地；  Tensorflow v1.5
  - [Paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf)
- [R-Net-in-Keras](https://github.com/YerevaNN/R-NET-in-Keras) -在Keras中重新实现R-NET.
   - 多发性硬化症;  非官方;  硬v2.0.6
  - [Paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf)
- [DrQA](https://github.com/hitvoice/DrQA) -DrQA是一种用于开放域问答的阅读理解系统.
   -Facebook；  官方;  pytorch v0.4
- [BERT](https://github.com/google-research/bert)  -一种新的语言表示模型，代表来自变压器的双向编码器表示.  与最新的语言表示模型不同，BERT被设计为通过在所有层的左和右上下文上共同进行条件预训练深度双向表示. 
   - 谷歌;  正式执行；  Tensorflow v1.11.0
  - [Paper](https://arxiv.org/abs/1810.04805)

## Lectures
- [Question Answering - Natural Language Processing](https://youtu.be/Kzi6tE4JaGo)  -Dragomir Radev博士  |  密西根大学  2016年.

## Slides
- [Question Answering with Knowledge Bases, Web and Beyond](https://github.com/scottyih/Slides/blob/master/QA%20Tutorial.pdf) - By Scott Wen-tau Yih & Hao Ma | Microsoft Research | 2016.
- [Question Answering](https://hpi.de/fileadmin/user_upload/fachgebiete/plattner/teaching/NaturalLanguageProcessing/NLP2017/NLP8_QuestionAnswering.pdf)  -博士  Mariana Neves |  哈索·普拉特纳学院|  2017.

## Dataset Collections
- [NLIWOD's Question answering datasets](https://github.com/dice-group/NLIWOD/tree/master/qa.datasets)
- [karthinkncode's Datasets for Natural Language Processing](https://github.com/karthikncode/nlp-datasets)

## Datasets
- [AI2 Science Questions v2.1(2017)](http://data.allenai.org/ai2-science-questions/)
   -它由美国小学和中学年级的学生评估中使用的问题组成.  每个问题均为4向选择题格式，可能包含也可能不包含图表元素.
  -论文：http：//ai2-website.s3.amazonaws.com/publications/AI2ReasoningChallenge2018.pdf
- [Children's Book Test](https://uclmr.github.io/ai4exams/data.html)
 -这是Facebook AI Research的bAbI项目之一，旨在实现自动文本理解和推理的目标.  CBT旨在直接衡量语言模型可以如何利用更广泛的语言环境.
- [CODAH Dataset](https://github.com/Websail-NU/CODAH)
- [DeepMind Q&A Dataset; CNN/Daily Mail](https://github.com/deepmind/rc-data)
   -Hermann等.  （2015）使用新闻文章创建了两个很棒的数据集，用于问答研究.  每个数据集包含许多文档（每个90k和197k），每个文档平均约有4个问题.  每个问题都是一个缺少一个单词/短语的句子，可以从随附的文档/上下文中找到.
  -论文：https：//arxiv.org/abs/1506.03340
- [ELI5](https://github.com/facebookresearch/ELI5)
  -论文：https：//arxiv.org/abs/1907.09190
- [GraphQuestions](https://github.com/ysu1989/GraphQuestions)
  -生成用于QA评估的特征丰富的问题​​集.
- [LC-QuAD](http://sda.cs.uni-bonn.de/projects/qa-dataset/)
   -这是一个黄金标准的KBQA（知识库问题回答）数据集，包含5000个Question和SPARQL查询.  LC-QuAD使用DBpedia v04.16作为目标KB.
- [MS MARCO](http://www.msmarco.org/dataset.aspx)
  -这是用于现实世界中的问题解答.
  -论文：https：//arxiv.org/abs/1611.09268
- [MultiRC](https://cogcomp.org/multirc/)
  -短段落和多句问题的数据集
  -论文：http：//cogcomp.org/page/publication_view/833 
- [NarrativeQA](https://github.com/deepmind/narrativeqa)
  -它包括带有Wikipedia摘要的文档列表，全文链接以及问题和解答.
  -论文：https：//arxiv.org/pdf/1712.07040v1.pdf
- [NewsQA](https://github.com/Maluuba/newsqa)
  -机器理解数据集
  -论文：https：//arxiv.org/pdf/1611.09830.pdf
- [Qestion-Answer Dataset by CMU](http://www.cs.cmu.edu/~ark/QA-data/)
   -这是Wikipedia文章的语料库，由它们手动生成的拟事实问题以及对这些问题的手动生成的答案，可用于学术研究.  这些数据由Noah Smith，Michael Heilman，Rebecca Hwa，Shay Cohen，Kevin Gimpel和卡耐基梅隆大学和匹兹堡大学的许多学生在2008年至2010年之间收集.
- [SQuAD1.0](https://rajpurkar.github.io/SQuAD-explorer/)
  -斯坦福问题解答数据集（SQuAD）是一种阅读理解数据集，由人群工作人员在一组Wikipedia文章上提出的问题组成，其中每个问题的答案是一段文本或跨度，来自相应的阅读文章或问题可能无法回答.
  -论文：https：//arxiv.org/abs/1606.05250
- [SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/)
   -SQuAD2.0将SQuAD1.1中的100,000个问题与50,000个新的，无法回答的问题相结合，这些问题是由人群工作者对抗性地编写的，看起来类似于可回答的问题.  为了在SQuAD2.0上取得出色的成绩，系统不仅必须在可能的情况下回答问题，而且还必须确定该段落何时不支持任何答案并放弃回答.
  -论文：https：//arxiv.org/abs/1806.03822
- [Story cloze test](http://cs.rochester.edu/nlp/rocstories/)
   -“故事完形填空测试”是一种新的常识推理框架，用于评估故事理解，故事生成和脚本学习.  此测试要求系统选择四句故事的正确结尾.
  -论文：https：//arxiv.org/abs/1604.01696
- [TriviaQA](http://nlp.cs.washington.edu/triviaqa/)
   -TriviaQA是一个阅读理解数据集，包含超过650K的问题-答案-证据三元组.  TriviaQA包括由琐事爱好者编写的95K问答对，并独立收集证据文件，每个问题平均六份，可为回答问题提供高质量的远程监管. 
  -论文：https：//arxiv.org/abs/1705.03551
- [WikiQA](https://www.microsoft.com/en-us/download/details.aspx?id=52419&from=https%3A%2F%2Fresearch.microsoft.com%2Fen-US%2Fdownloads%2F4495da01-db8c-4041-a7f6-7984a4f6a905%2Fdefault.aspx)
  -开放域问题解答的一组公开可用的问题和句子对.
  
### The DeepQA Research Team in IBM Watson's publication within 5 years
- 2015
  -“通过IBM Watson中的电子病历自动生成问题清单”，Murthy Devarakonda，邹静慧，IAAI，2015年.
  -“ IBM Watson问题解答中的决策制定”，J.William Murdock，本体论峰会，2015年.
  - ["Unsupervised Entity-Relation Analysis in IBM Watson"](http://www.cogsys.org/papers/ACS2015/article12.pdf)，阿迪亚·卡良布尔（Aditya Kalyanpur），威廉姆多克（J William Murdock），ACS，2015年.
  -“常识推理：基于事件演算的方法”，ET Mueller，摩根·考夫曼/爱思唯尔，2015年.
- 2014
  -“问题导向的患者记录摘要：关于Watson应用程序的早期报告”，M.Devarakonda，张东阳，Tsing-Huei Tsou，M.Bornea，Healthcom，2014年.
  - ["WatsonPaths: Scenario-based Question Answering and Inference over Unstructured Information"](http://domino.watson.ibm.com/library/Cyberdig.nsf/1e4115aea78b6e7c85256b360066f0d4/088f74984a07645485257d5f006ace96!OpenDocument&Highlight=0,RC25489)，亚当·拉利（Adam Lally），苏加托·巴基（Sugato Bachi），迈克尔·巴博拉克（Michael A.Barborak），大卫·W·布坎南（David W. M.Prager，Christopher A.Welty，IBM研究报告RC25489,2014年.
  - ["Medical Relation Extraction with Manifold Models"](http://acl2014.org/acl2014/P14-1/pdf/P14-1078.pdf)，王Chang和范范（ACL），2014年.

### MS Research's publication within 5 years
- 2018
  -“人与人交流中的表征和支持问题解答”，肖扬，艾哈迈德·哈桑·阿瓦达拉，马甸·哈布萨，王伟，王妙森，ACM SIGIR，2018年.
  - ["FigureQA: An Annotated Figure Dataset for Visual Reasoning"](https://arxiv.org/abs/1710.07300)，Samira Ebrahimi Kahou，Vincent Michalski，Adam Atkinson，Akos Rate，Adam Trischler，Yoshua Bengio，ICLR，2018年
- 2017
  - "Multi-level Attention Networks for Visual Question Answering", Dongfei Yu, Jianlong Fu, Tao Mei, Yong Rui, CVPR, 2017.
  -“用于问答和问题生成的联合模型”，王彤，袁兴迪，亚当·特里斯勒，ICML，2017年.
  -“机器学习中用于转移学习的两阶段综合网络”，David Golub，黄宝森，何晓东，李登，EMNLP，2017年.
  -“通过语法可解释的表示进行问题解答”，哈米德·帕兰吉，保罗·斯莫伦斯基，何小东，李登， 
  -“基于搜索的神经网络学习，用于顺序问题解答”，Mohit Iyyer，叶文陶，张明伟，ACL，2017年.
- 2016
  - ["Stacked Attention Networks for Image Question Answering"](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Yang_Stacked_Attention_Networks_CVPR_2016_paper.html), Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola, CVPR, 2016.
  - ["Question Answering with Knowledge Base, Web and Beyond"](https://www.microsoft.com/en-us/research/publication/question-answering-with-knowledge-base-web-and-beyond/), Yih, Scott Wen-tau and Ma, Hao, ACM SIGIR, 2016.
  - ["NewsQA: A Machine Comprehension Dataset"](https://arxiv.org/abs/1611.09830)，亚当·特里斯勒（Adam Trischler），王彤，袁星迪，贾斯汀·哈里斯（Justin Harris），亚历山德罗·索多尼（Alessandro Sordoni），菲利普·巴赫曼（Philip Bachman），凯希尔·苏莱曼（Kaheer Suleman），RepL4NLP，2016年.
  - ["Table Cell Search for Question Answering"](https://dl.acm.org/citation.cfm?id=2883080), Sun, Huan and Ma, Hao and He, Xiaodong and Yih, Wen-tau and Su, Yu and Yan, Xifeng, WWW, 2016.
- 2015
  - ["WIKIQA: A Challenge Dataset for Open-Domain Question Answering"](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/YangYihMeek_EMNLP-15_WikiQA.pdf)，Yi Yang，Yi-wen-tau和Christopher Meek，EMNLP，2015年.
  - ["Web-based Question Answering: Revisiting AskMSR"](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/AskMSRPlusTR_082815.pdf)，蔡辰昌，叶文陶和克里斯托弗·J·C·伯吉斯（MSRF-TR），2015年.
  - ["Open Domain Question Answering via Semantic Enrichment"](https://dl.acm.org/citation.cfm?id=2741651), Huan Sun, Hao Ma, Wen-tau Yih, Chen-Tse Tsai, Jingjing Liu, and Ming-Wei Chang, WWW, 2015.
- 2014
  - ["An Overview of Microsoft Deep QA System on Stanford WebQuestions Benchmark"](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Microsoft20Deep20QA.pdf), Zhenghao Wang, Shengquan Yan, Huaming Wang, and Xuedong Huang, MSR-TR, 2014.
  -[“针对单关系问题的语义解析”]（），叶文涛，何晓东，克里斯托弗·米克，ACL，2014年.
  
### Google AI's publication within 5 years
- 2018
  -Google质量检查<a name="qanet"></a>
    - ["QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension"](https://openreview.net/pdf?id=B14TlG-RW)，Adams Wei Yu，David Dohan，Minh-Thang Luong，Rui Zhao，陈凯，Mohammad Norouzi，Quoc V.Le，ICLR，2018.
    - ["Ask the Right Questions: Active Question Reformulation with Reinforcement Learning"](https://openreview.net/pdf?id=S1CChZ-CZ)，克里斯蒂安·巴克（Christian Buck）和简尼斯·布利安（Jannis Bulian）以及马西米利亚诺·西亚里亚米塔（Massimiliano Ciaramita）和WojciechPawełGajewski，安德烈·格斯蒙多（Andrea Gesmundo），尼尔·霍尔斯比（Neil Houlsby）和王玮，ICLR，2018年.
    - ["Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors"](https://arxiv.org/pdf/1612.04342.pdf)，Radu Soricut，南鼎，2018.
  -句子表示
    - ["An efficient framework for learning sentence representations"](https://arxiv.org/pdf/1803.02893.pdf)，Lajanugen Logeswaran，Lee Honglak Lee，ICLR，2018年.
  - ["Did the model understand the question?"](https://arxiv.org/pdf/1805.05492.pdf)，Pramod K.Mudrakarta和Ankur Taly和Mukund Sundararajan和Kedar Dhamdhere，ACL，2018年.
- 2017
  - ["Analyzing Language Learned by an Active Question Answering Agent"](https://arxiv.org/pdf/1801.07537.pdf)，克里斯蒂安·巴克（Christian Buck）和简尼斯·布利安（Jannis Bulian），马西米利亚诺·西亚里亚米塔（Massimiliano Ciaramita），沃伊切奇·加耶夫斯基（Wojciech Gajewski），安德里亚·格斯蒙多（Andrea Gesmundo），尼尔·霍尔斯比（Neil Houlsby）和王玮，NIPS，2017
  - ["Learning Recurrent Span Representations for Extractive Question Answering"](https://arxiv.org/pdf/1611.01436.pdf)，Kenton Lee和Shimi Salant以及Tom Kwiatkowski和Ankur Parikh以及Dipanjan Das和Jonathan Berant，ICLR，2017年.
  -确定相同的问题
    - ["Neural Paraphrase Identification of Questions with Noisy Pretraining"](https://arxiv.org/pdf/1704.04565.pdf)，Gaurav Singh Tomar和Thyago Duque和OscarTäckström和Jakob Uszkoreit和Dipa​​njan Das，SCLeM，2017年.
- 2014
  -“伟大的问题！社区问答中的问题质量”，Sujith Ravi和Bo Pang以及Vibhor Rastogi和Ravi Kumar，ICWSM，2014年.

### Facebook AI Research's publication within 5 years
- 2018
  - [Embodied Question Answering](https://research.fb.com/publications/embodied-question-answering/)，Abhishek Das，Samyak Datta，Georgia Gkioxari，Stefan Lee，Devi Parikh和Dhruv Batra，CVPR，2018年
  - [Do explanations make VQA models more predictable to a human?](https://research.fb.com/publications/do-explanations-make-vqa-models-more-predictable-to-a-human/)，Arjun Chandrasekaran，Viraj Prabhu，Deshraj Yadav，Prithvijit Chattopadhyay和Devi Parikh，EMNLP，2018年
  - [Neural Compositional Denotational Semantics for Question Answering](https://research.fb.com/publications/neural-compositional-denotational-semantics-for-question-answering/)，Nitish Gupta，Mike Lewis，EMNLP，2018年
- 2017
  -DrQA <a name="drqa"></a>
    - [Reading Wikipedia to Answer Open-Domain Questions](https://cs.stanford.edu/people/danqi/papers/acl2017.pdf)，Danqi Chen，Adam Fisch，Jason Weston和Antoine Bordes，ACL，2017年.

## Books
-自然语言问答系统平装本-Boris Galitsky（2003）
-问题解答的新方向-Mark T. Maybury（2004）
-第3部分.5.牛津大学计算语言学手册中的问题解答-桑达·哈拉巴久和丹·摩尔多瓦（2005）
-第28章语音和语言处理中的问答-Daniel Jurafsky和James H.Martin（2017）

## Links
- [Building a Question-Answering System from Scratch— Part 1](https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507)
- [Qeustion Answering with Tensorflow By Steven Hewitt, O'REILLY, 2017](https://www.oreilly.com/ideas/question-answering-with-tensorflow)
- [Why question answering is hard](http://nicklothian.com/blog/2014/09/25/why-question-answering-is-hard/)


## Contributing

 欢迎捐款！  阅读 [contribution guidelines](https://github.com/seriousran/awesome-qa/blob/master/contributing.md) 第一.

## License
[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/share-your-work/public-domain/cc0/)

在法律允许的范围内， [seriousmac](https://github.com/seriousmac) （维护者）已放弃此作品的所有版权以及相关或邻近的权利.
