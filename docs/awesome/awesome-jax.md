<div class="github-widget" data-repo="n2cholas/awesome-jax"></div>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-6890694312814945" data-ad-slot="5473692530" data-ad-format="auto"  data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
<!--lint ignore double-link-->

<!--lint ignore double-link-->
[JAX](https://github.com/google/jax) å¸¦æ¥è‡ªåŠ¨å¾®åˆ†å’Œ [XLA compiler](https://www.tensorflow.org/xla) ä¸€èµ·é€šè¿‡ [NumPy](https://numpy.org/)ç±»ä¼¼ APIï¼Œç”¨äºåœ¨ GPU å’Œ TPU ç­‰åŠ é€Ÿå™¨ä¸Šè¿›è¡Œé«˜æ€§èƒ½æœºå™¨å­¦ä¹ ç ”ç©¶.
<!--lint enable double-link-->

è¿™æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„ JAX åº“ã€é¡¹ç›®å’Œå…¶ä»–èµ„æºçš„ç²¾é€‰åˆ—è¡¨. æ¬¢è¿æŠ•ç¨¿ï¼



<a name="libraries" />

## Libraries

- ç¥ç»ç½‘ç»œåº“
    - [Flax](https://raw.githubusercontent.com/google/flax) - ä»¥çµæ´»æ€§å’Œæ¸…æ™°åº¦ä¸ºä¸­å¿ƒ. <img src="https://img.shields.io/github/stars/google/flax?style=social" align="center">
    - [Haiku](https://raw.githubusercontent.com/deepmind/dm-haiku) - ä¸“æ³¨äºç®€å•æ€§ï¼Œç”± DeepMind çš„ Sonnet ä½œè€…åˆ›å»º. <img src="https://img.shields.io/github/stars/deepmind/dm-haiku?style=social" align="center">
    - [Objax](https://raw.githubusercontent.com/google/objax) - å…·æœ‰ç±»ä¼¼äº PyTorch çš„é¢å‘å¯¹è±¡è®¾è®¡. <img src="https://img.shields.io/github/stars/google/objax?style=social" align="center">
    - [Elegy](https://poets-ai.github.io/elegy/)  - JAX ä¸­æ·±åº¦å­¦ä¹ çš„é«˜çº§ API. æ”¯æŒ Flaxã€Haiku å’Œ Optax. <img src="https://img.shields.io/github/stars/poets-ai/elegy?style=social" align="center">
    - [Trax](https://raw.githubusercontent.com/google/trax) - â€œBatteries includedâ€æ·±åº¦å­¦ä¹ åº“ä¸“æ³¨äºä¸ºå¸¸è§å·¥ä½œè´Ÿè½½æä¾›è§£å†³æ–¹æ¡ˆ. <img src="https://img.shields.io/github/stars/google/trax?style=social" align="center">
    - [Jraph](https://raw.githubusercontent.com/deepmind/jraph) - è½»é‡çº§å›¾å½¢ç¥ç»ç½‘ç»œåº“. <img src="https://img.shields.io/github/stars/deepmind/jraph?style=social" align="center">
    - [Neural Tangents](https://raw.githubusercontent.com/google/neural-tangents) - ç”¨äºæŒ‡å®šæœ‰é™å’Œ_æ— é™_å®½åº¦çš„ç¥ç»ç½‘ç»œçš„é«˜çº§ API. <img src="https://img.shields.io/github/stars/google/neural-tangents?style=social" align="center">
    - [HuggingFace](https://raw.githubusercontent.com/huggingface/transformers) - ç”¨äºå„ç§è‡ªç„¶è¯­è¨€ä»»åŠ¡çš„é¢„è®­ç»ƒ Transformer ç”Ÿæ€ç³»ç»Ÿ (Flax). <img src="https://img.shields.io/github/stars/huggingface/transformers?style=social" align="center">
    - [Equinox](https://raw.githubusercontent.com/patrick-kidger/equinox) - å¯è°ƒç”¨çš„ PyTrees å’Œè¿‡æ»¤çš„ JIT/grad è½¬æ¢ =&gt; JAX ä¸­çš„ç¥ç»ç½‘ç»œ. <img src="https://img.shields.io/github/stars/patrick-kidger/equinox?style=social" align="center">
- [NumPyro](https://raw.githubusercontent.com/pyro-ppl/numpyro) - åŸºäº Pyro åº“çš„æ¦‚ç‡ç¼–ç¨‹. <img src="https://img.shields.io/github/stars/pyro-ppl/numpyro?style=social" align="center">
- [Chex](https://raw.githubusercontent.com/deepmind/chex) - ç”¨äºç¼–å†™å’Œæµ‹è¯•å¯é  JAX ä»£ç çš„å®ç”¨ç¨‹åº. <img src="https://img.shields.io/github/stars/deepmind/chex?style=social" align="center">
- [Optax](https://raw.githubusercontent.com/deepmind/optax) - æ¢¯åº¦å¤„ç†å’Œä¼˜åŒ–åº“. <img src="https://img.shields.io/github/stars/deepmind/optax?style=social" align="center">
- [RLax](https://raw.githubusercontent.com/deepmind/rlax) - ç”¨äºå®æ–½å¼ºåŒ–å­¦ä¹ ä»£ç†çš„åº“. <img src="https://img.shields.io/github/stars/deepmind/rlax?style=social" align="center">
- [JAX, M.D.](https://raw.githubusercontent.com/google/jax-md) - åŠ é€Ÿçš„å¾®åˆ†åˆ†å­åŠ¨åŠ›å­¦. <img src="https://img.shields.io/github/stars/google/jax-md?style=social" align="center">
- [Coax](https://raw.githubusercontent.com/coax-dev/coax) - å°† RL è®ºæ–‡è½¬åŒ–ä¸ºä»£ç ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•çš„æ–¹æ³•. <img src="https://img.shields.io/github/stars/coax-dev/coax?style=social" align="center">
- [Distrax](https://raw.githubusercontent.com/deepmind/distrax) - é‡æ–°å®ç° TensorFlow Probabilityï¼ŒåŒ…å«æ¦‚ç‡åˆ†å¸ƒå’ŒåŒå°„å™¨. <img src="https://img.shields.io/github/stars/deepmind/distrax?style=social" align="center">
- [cvxpylayers](https://raw.githubusercontent.com/cvxgrp/cvxpylayers) - æ„å»ºå¯åŒºåˆ†çš„å‡¸ä¼˜åŒ–å±‚. <img src="https://img.shields.io/github/stars/cvxgrp/cvxpylayers?style=social" align="center">
- [TensorLy](https://raw.githubusercontent.com/tensorly/tensorly) - å¼ é‡å­¦ä¹ å˜å¾—ç®€å•. <img src="https://img.shields.io/github/stars/tensorly/tensorly?style=social" align="center">
- [NetKet](https://raw.githubusercontent.com/netket/netket) - é‡å­ç‰©ç†å­¦æœºå™¨å­¦ä¹ å·¥å…·ç®±. <img src="https://img.shields.io/github/stars/netket/netket?style=social" align="center">
- [Fortuna](https://raw.githubusercontent.com/awslabs/fortuna) - ç”¨äºæ·±åº¦å­¦ä¹ ä¸­ä¸ç¡®å®šæ€§é‡åŒ–çš„ AWS åº“. <img src="https://img.shields.io/github/stars/awslabs/fortuna?style=social" align="center">

<a name="new-libraries" />

### New Libraries

æœ¬èŠ‚åŒ…å«åˆ¶ä½œç²¾è‰¯ä¸”æœ‰ç”¨çš„åº“ï¼Œä½†ä¸ä¸€å®šç»è¿‡å¤§é‡ç”¨æˆ·ç¾¤çš„å®æˆ˜æµ‹è¯•.

- ç¥ç»ç½‘ç»œåº“
    - [FedJAX](https://raw.githubusercontent.com/google/fedjax) - åŸºäº Optax å’Œ Haiku æ„å»ºçš„ JAX è”åˆå­¦ä¹ . <img src="https://img.shields.io/github/stars/google/fedjax?style=social" align="center">
    - [Equivariant MLP](https://raw.githubusercontent.com/mfinzi/equivariant-MLP) - æ„å»ºç­‰å˜ç¥ç»ç½‘ç»œå±‚. <img src="https://img.shields.io/github/stars/mfinzi/equivariant-MLP?style=social" align="center">
    - [jax-resnet](https://raw.githubusercontent.com/n2cholas/jax-resnet/) - Flax ä¸­ ResNet å˜ä½“çš„å®ç°å’Œæ£€æŸ¥ç‚¹. <img src="https://img.shields.io/github/stars/n2cholas/jax-resnet?style=social" align="center">
    - [Parallax](https://raw.githubusercontent.com/srush/parallax) - JAX çš„ä¸å¯å˜ Torch æ¨¡å—. <img src="https://img.shields.io/github/stars/srush/parallax?style=social" align="center">
- [jax-unirep](https://raw.githubusercontent.com/ElArkk/jax-unirep) - å›¾ä¹¦é¦†å®æ–½ [UniRep model](https://www.nature.com/articles/s41592-019-0598-1) ç”¨äºè›‹ç™½è´¨æœºå™¨å­¦ä¹ åº”ç”¨. <img src="https://img.shields.io/github/stars/ElArkk/jax-unirep?style=social" align="center">
- [jax-flows](https://raw.githubusercontent.com/ChrisWaites/jax-flows) - è§„èŒƒåŒ– JAX ä¸­çš„æµç¨‹. <img src="https://img.shields.io/github/stars/ChrisWaites/jax-flows?style=social" align="center">
- [sklearn-jax-kernels](https://raw.githubusercontent.com/ExpectationMax/sklearn-jax-kernels) - ä½¿ç”¨ JAX çš„ `scikit-learn` å†…æ ¸çŸ©é˜µ. <img src="https://img.shields.io/github/stars/ExpectationMax/sklearn-jax-kernels?style=social" align="center">
- [jax-cosmo](https://raw.githubusercontent.com/DifferentiableUniverseInitiative/jax_cosmo) - å¯åŒºåˆ†çš„å®‡å®™å­¦åº“. <img src="https://img.shields.io/github/stars/DifferentiableUniverseInitiative/jax_cosmo?style=social" align="center">
- [efax](https://raw.githubusercontent.com/NeilGirdhar/efax) - JAX ä¸­çš„æŒ‡æ•°æ—. <img src="https://img.shields.io/github/stars/NeilGirdhar/efax?style=social" align="center">
- [mpi4jax](https://raw.githubusercontent.com/PhilipVinc/mpi4jax) - å°† MPI æ“ä½œä¸ CPU å’Œ GPU ä¸Šçš„ Jax ä»£ç ç›¸ç»“åˆ. <img src="https://img.shields.io/github/stars/PhilipVinc/mpi4jax?style=social" align="center">
- [imax](https://raw.githubusercontent.com/4rtemi5/imax) - å›¾åƒå¢å¼ºå’Œè½¬æ¢. <img src="https://img.shields.io/github/stars/4rtemi5/imax?style=social" align="center">
- [FlaxVision](https://raw.githubusercontent.com/rolandgvc/flaxvision) - äºšéº»ç‰ˆçš„ TorchVision. <img src="https://img.shields.io/github/stars/rolandgvc/flaxvision?style=social" align="center">
- [Oryx](https://github.com/tensorflow/probability/tree/master/spinoffs/oryx) - åŸºäºç¨‹åºè½¬æ¢çš„æ¦‚ç‡ç¼–ç¨‹è¯­è¨€.
- [Optimal Transport Tools](https://github.com/google-research/ott) - æ†ç»‘å®ç”¨ç¨‹åºä»¥è§£å†³æœ€ä½³è¿è¾“é—®é¢˜çš„å·¥å…·ç®±.
- [delta PV](https://raw.githubusercontent.com/romanodev/deltapv) - å…·æœ‰è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½çš„å…‰ä¼æ¨¡æ‹Ÿå™¨. <img src="https://img.shields.io/github/stars/romanodev/deltapv?style=social" align="center">
- [jaxlie](https://raw.githubusercontent.com/brentyi/jaxlie) - ç”¨äºåˆšä½“å˜æ¢å’Œä¼˜åŒ–çš„è°è¨€ç†è®ºåº“. <img src="https://img.shields.io/github/stars/brentyi/jaxlie?style=social" align="center">
- [BRAX](https://raw.githubusercontent.com/google/brax) - ç”¨äºæ¨¡æ‹Ÿç¯å¢ƒçš„å¾®åˆ†ç‰©ç†å¼•æ“ä»¥åŠç”¨äºä¸ºè¿™äº›ç¯å¢ƒè®­ç»ƒä»£ç†çš„å­¦ä¹ ç®—æ³•. <img src="https://img.shields.io/github/stars/google/brax?style=social" align="center">
- [flaxmodels](https://raw.githubusercontent.com/matthias-wright/flaxmodels) - Jax/Flax çš„é¢„è®­ç»ƒæ¨¡å‹. <img src="https://img.shields.io/github/stars/matthias-wright/flaxmodels?style=social" align="center">
- [CR.Sparse](https://raw.githubusercontent.com/carnotresearch/cr-sparse) - ç”¨äºç¨€ç–è¡¨ç¤ºå’Œå‹ç¼©æ„ŸçŸ¥çš„ XLA åŠ é€Ÿç®—æ³•. <img src="https://img.shields.io/github/stars/carnotresearch/cr-sparse?style=social" align="center">
- [exojax](https://raw.githubusercontent.com/HajimeKawahara/exojax) - ä¸ JAX å…¼å®¹çš„ç³»å¤–è¡Œæ˜Ÿ/è¤çŸ®æ˜Ÿçš„è‡ªåŠ¨å¯å¾®å…‰è°±å»ºæ¨¡. <img src="https://img.shields.io/github/stars/HajimeKawahara/exojax?style=social" align="center">
- [JAXopt](https://raw.githubusercontent.com/google/jaxopt) - JAX ä¸­çš„ç¡¬ä»¶åŠ é€Ÿ (GPU/TPU)ã€å¯æ‰¹å¤„ç†å’Œå¯åŒºåˆ†çš„ä¼˜åŒ–å™¨. <img src="https://img.shields.io/github/stars/google/jaxopt?style=social" align="center">
- [PIX](https://raw.githubusercontent.com/deepmind/dm_pix) - PIX æ˜¯ JAX ä¸­çš„å›¾åƒå¤„ç†åº“ï¼Œç”¨äº JAX. <img src="https://img.shields.io/github/stars/deepmind/dm_pix?style=social" align="center">
- [bayex](https://raw.githubusercontent.com/alonfnt/bayex) - ç”± JAX æä¾›æ”¯æŒçš„è´å¶æ–¯ä¼˜åŒ–. <img src="https://img.shields.io/github/stars/alonfnt/bayex?style=social" align="center">
- [JaxDF](https://raw.githubusercontent.com/ucl-bug/jaxdf) - å…·æœ‰ä»»æ„ç¦»æ•£åŒ–çš„å¯åŒºåˆ†æ¨¡æ‹Ÿå™¨çš„æ¡†æ¶. <img src="https://img.shields.io/github/stars/ucl-bug/jaxdf?style=social" align="center">
- [tree-math](https://raw.githubusercontent.com/google/tree-math) - å°†å¯¹æ•°ç»„è¿›è¡Œæ“ä½œçš„å‡½æ•°è½¬æ¢ä¸ºå¯¹ PyTrees è¿›è¡Œæ“ä½œçš„å‡½æ•°. <img src="https://img.shields.io/github/stars/google/tree-math?style=social" align="center">
- [jax-models](https://raw.githubusercontent.com/DarshanDeshpande/jax-models) - æœ€åˆæ²¡æœ‰ä»£ç æˆ–ä½¿ç”¨ JAX ä»¥å¤–çš„æ¡†æ¶ç¼–å†™çš„ä»£ç çš„ç ”ç©¶è®ºæ–‡çš„å®ç°. <img src="https://img.shields.io/github/stars/DarshanDeshpande/jax-modelsa?style=social" align="center">
- [PGMax](https://raw.githubusercontent.com/vicariousinc/PGMax) - ç”¨äºæ„å»ºç¦»æ•£æ¦‚ç‡å›¾å½¢æ¨¡å‹ (PGM) å¹¶é€šè¿‡ JAX å¯¹å…¶è¿è¡Œæ¨ç†çš„æ¡†æ¶. <img src="https://img.shields.io/github/stars/vicariousinc/pgmax?style=social" align="center">
- [EvoJAX](https://raw.githubusercontent.com/google/evojax) - ç¡¬ä»¶åŠ é€Ÿçš„ç¥ç»è¿›åŒ– <img src="https://img.shields.io/github/stars/google/evojax?style=social" align="center">
- [evosax](https://raw.githubusercontent.com/RobertTLange/evosax) - åŸºäº JAX çš„è¿›åŒ–ç­–ç•¥ <img src="https://img.shields.io/github/stars/RobertTLange/evosax?style=social" align="center">
- [SymJAX](https://raw.githubusercontent.com/SymJAX/SymJAX) - ç¬¦å· CPU/GPU/TPU ç¼–ç¨‹. <img src="https://img.shields.io/github/stars/SymJAX/SymJAX?style=social" align="center">
- [mcx](https://raw.githubusercontent.com/rlouf/mcx) - è¡¨è¾¾å’Œç¼–è¯‘ç”¨äºæ€§èƒ½æ¨ç†çš„æ¦‚ç‡ç¨‹åº. <img src="https://img.shields.io/github/stars/rlouf/mcx?style=social" align="center">
- [Einshape](https://raw.githubusercontent.com/deepmind/einshape) - ç”¨äº JAX å’Œå…¶ä»–æ¡†æ¶çš„åŸºäº DSL çš„é‡å¡‘åº“. <img src="https://img.shields.io/github/stars/deepmind/einshape?style=social" align="center">
- [ALX](https://github.com/google-research/google-research/tree/master/alx) - ä½¿ç”¨äº¤æ›¿æœ€å°äºŒä¹˜æ³•è¿›è¡Œåˆ†å¸ƒå¼çŸ©é˜µåˆ†è§£çš„å¼€æºåº“ï¼Œæ›´å¤šä¿¡æ¯åœ¨ [_ALX: Large Scale Matrix Factorization on TPUs_](https://arxiv.org/abs/2112.02194).
- [Diffrax](https://raw.githubusercontent.com/patrick-kidger/diffrax) - JAX ä¸­çš„æ•°å€¼å¾®åˆ†æ–¹ç¨‹æ±‚è§£å™¨. <img src="https://img.shields.io/github/stars/patrick-kidger/diffrax?style=social" align="center">
- [tinygp](https://raw.githubusercontent.com/dfm/tinygp) - JAX ä¸­æœ€ç²¾ç®€çš„ Gaussian è¿‡ç¨‹åº“. <img src="https://img.shields.io/github/stars/dfm/tinygp?style=social" align="center">
- [gymnax](https://raw.githubusercontent.com/RobertTLange/gymnax) - å…·æœ‰è‘—åå¥èº«æˆ¿ API çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ. <img src="https://img.shields.io/github/stars/RobertTLange/gymnax?style=social" align="center">
- [Mctx](https://raw.githubusercontent.com/deepmind/mctx) - æœ¬æœº JAX ä¸­çš„è’™ç‰¹å¡ç½—æ ‘æœç´¢ç®—æ³•. <img src="https://img.shields.io/github/stars/deepmind/mctx?style=social" align="center">
- [KFAC-JAX](https://raw.githubusercontent.com/deepmind/kfac-jax) - ç¥ç»ç½‘ç»œè¿‘ä¼¼æ›²ç‡çš„äºŒé˜¶ä¼˜åŒ–. <img src="https://img.shields.io/github/stars/deepmind/kfac-jax?style=social" align="center">
- [TF2JAX](https://raw.githubusercontent.com/deepmind/tf2jax) - å°†å‡½æ•°/å›¾å½¢è½¬æ¢ä¸º JAX å‡½æ•°. <img src="https://img.shields.io/github/stars/deepmind/tf2jax?style=social" align="center">
- [jwave](https://raw.githubusercontent.com/ucl-bug/jwave) - å¯åŒºåˆ†å£°å­¦æ¨¡æ‹Ÿåº“ <img src="https://img.shields.io/github/stars/ucl-bug/jwave?style=social" align="center">
- [GPJax](https://github.com/thomaspinder/GPJax) - JAX ä¸­çš„é«˜æ–¯è¿‡ç¨‹.
- [Jumanji](https://raw.githubusercontent.com/instadeepai/jumanji) - ä¸€å¥—ç”¨ JAX ç¼–å†™çš„è¡Œä¸šé©±åŠ¨çš„ç¡¬ä»¶åŠ é€Ÿ RL ç¯å¢ƒ. <img src="https://img.shields.io/github/stars/instadeepai/jumanji?style=social" align="center">
- [Eqxvision](https://raw.githubusercontent.com/paganpasta/eqxvision) - ç«ç‚¬è§†è§‰çš„ Equinox ç‰ˆæœ¬. <img src="https://img.shields.io/github/stars/paganpasta/eqxvision?style=social" align="center">
- [JAXFit](https://raw.githubusercontent.com/dipolar-quantum-gases/jaxfit) - ç”¨äºéçº¿æ€§æœ€å°äºŒä¹˜é—®é¢˜çš„åŠ é€Ÿæ›²çº¿æ‹Ÿåˆåº“ï¼ˆå‚è§ [arXiv paper](https://arxiv.org/abs/2208.12187)). <img src="https://img.shields.io/github/stars/dipolar-quantum-gases/jaxfit?style=social" align="center">
- [econpizza](https://raw.githubusercontent.com/gboehl/econpizza) - ä½¿ç”¨ JAX è§£å†³å…·æœ‰å¼‚æ„ä»£ç†çš„å®è§‚ç»æµæ¨¡å‹. <img src="https://img.shields.io/github/stars/gboehl/econpizza?style=social" align="center">
- [SPU](https://raw.githubusercontent.com/secretflow/spu) - ç‰¹å®šé¢†åŸŸçš„ç¼–è¯‘å™¨å’Œè¿è¡Œæ—¶å¥—ä»¶ï¼Œç”¨äºä½¿ç”¨ MPCï¼ˆå®‰å…¨å¤šæ–¹è®¡ç®—ï¼‰è¿è¡Œ JAX ä»£ç . <img src="https://img.shields.io/github/stars/secretflow/spu?style=social" align="center">

<a name="models-and-projects" />

## Models and Projects

### JAX

- [Fourier Feature Networks](https://github.com/tancik/fourier-feature-networks) - æ­£å¼å®æ–½ [_Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains_](https://people.eecs.berkeley.edu/~bmild/fourfeat).
- [kalman-jax](https://github.com/AaltoML/kalman-jax) - ä½¿ç”¨è¿­ä»£å¡å°”æ›¼æ»¤æ³¢å’Œå¹³æ»‘å¯¹é©¬å°”å¯å¤«ï¼ˆå³æ—¶é—´ï¼‰é«˜æ–¯è¿‡ç¨‹è¿›è¡Œè¿‘ä¼¼æ¨æ–­.
- [jaxns](https://github.com/Joshuaalbert/jaxns) - JAX ä¸­çš„åµŒå¥—é‡‡æ ·.
- [Amortized Bayesian Optimization](https://github.com/google-research/google-research/tree/master/amortized_bo) - ç›¸å…³ä»£ç  [_Amortized Bayesian Optimization over Discrete Spaces_](http://www.auai.org/uai2020/proceedings/329_main_paper.pdf).
- [Accurate Quantized Training](https://github.com/google-research/google-research/tree/master/aqt) - ç”¨äºåœ¨ JAX å’Œ Flax ä¸­è¿è¡Œå’Œåˆ†æç¥ç»ç½‘ç»œé‡åŒ–å®éªŒçš„å·¥å…·å’Œåº“.
- [BNN-HMC](https://github.com/google-research/google-research/tree/master/bnn_hmc) - è®ºæ–‡çš„å®æ–½ [_What Are Bayesian Neural Network Posteriors Really Like?_](https://arxiv.org/abs/2104.14421).
- [JAX-DFT](https://github.com/google-research/google-research/tree/master/jax_dft) - JAXä¸­çš„ä¸€ç»´å¯†åº¦æ³›å‡½ç†è®ºï¼ˆDFTï¼‰ï¼Œå®ç° [_Kohn-Sham equations as regularizer: building prior knowledge into machine-learned physics_](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.126.036401).
- [Robust Loss](https://github.com/google-research/google-research/tree/master/robust_loss_jax) - Reference code for the paper [_A General and Adaptive Robust Loss Function_](https://arxiv.org/abs/1701.03077).
- [Symbolic Functionals](https://github.com/google-research/google-research/tree/master/symbolic_functionals) - ç¤ºèŒƒæ¥è‡ª [_Evolving symbolic density functionals_](https://arxiv.org/abs/2203.02540).
- [TriMap](https://github.com/google-research/google-research/tree/master/trimap) - å®˜æ–¹ JAX å®ç° [_TriMap: Large-scale Dimensionality Reduction Using Triplets_](https://arxiv.org/abs/1910.00204).

### Flax

- [Performer](https://github.com/google-research/google-research/tree/master/performer/fast_attention/jax) - Performerï¼ˆé€šè¿‡ FAVOR+ çš„çº¿æ€§å˜å‹å™¨ï¼‰æ¶æ„çš„ Flax å®ç°.
- [JaxNeRF](https://github.com/google-research/google-research/tree/master/jaxnerf) - å®æ–½ [_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis_](http://www.matthewtancik.com/nerf) å…·æœ‰å¤šè®¾å¤‡ GPU/TPU æ”¯æŒ.
- [mip-NeRF](https://github.com/google/mipnerf) - æ­£å¼å®æ–½ [_Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields_](https://jonbarron.info/mipnerf).
- [RegNeRF](https://github.com/google-research/google-research/tree/master/regnerf) - æ­£å¼å®æ–½ [_RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs_](https://m-niemeyer.github.io/regnerf/).
- [Big Transfer (BiT)](https://github.com/google-research/big_transfer) - å®æ–½ [_Big Transfer (BiT): General Visual Representation Learning_](https://arxiv.org/abs/1912.11370).
- [JAX RL](https://github.com/ikostrikov/jax-rl) - å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å®ç°.
- [gMLP](https://github.com/SauravMaheshkar/gMLP) - å®æ–½ [_Pay Attention to MLPs_](https://arxiv.org/abs/2105.08050).
- [MLP Mixer](https://github.com/SauravMaheshkar/MLP-Mixer) - æœ€å°çš„å®æ–½ [_MLP-Mixer: An all-MLP Architecture for Vision_](https://arxiv.org/abs/2105.01601).
- [Distributed Shampoo](https://github.com/google-research/google-research/tree/master/scalable_shampoo) - å®æ–½ [_Second Order Optimization Made Practical_](https://arxiv.org/abs/2002.09018).
- [NesT](https://github.com/google-research/nested-transformer) - æ­£å¼å®æ–½ [_Aggregating Nested Transformers_](https://arxiv.org/abs/2105.12723).
- [XMC-GAN](https://github.com/google-research/xmcgan_image_generation) - æ­£å¼å®æ–½ [_Cross-Modal Contrastive Learning for Text-to-Image Generation_](https://arxiv.org/abs/2101.04702).
- [FNet](https://github.com/google-research/google-research/tree/master/f_net) - æ­£å¼å®æ–½ [_FNet: Mixing Tokens with Fourier Transforms_](https://arxiv.org/abs/2105.03824).
- [GFSA](https://github.com/google-research/google-research/tree/master/gfsa) - æ­£å¼å®æ–½ [_Learning Graph Structure With A Finite-State Automaton Layer_](https://arxiv.org/abs/2007.04929).
- [IPA-GNN](https://github.com/google-research/google-research/tree/master/ipagnn) - æ­£å¼å®æ–½ [_Learning to Execute Programs with Instruction Pointer Attention Graph Neural Networks_](https://arxiv.org/abs/2010.12621).
- [Flax Models](https://github.com/google-research/google-research/tree/master/flax_models) - åœ¨ Flax ä¸­å®ç°çš„æ¨¡å‹å’Œæ–¹æ³•çš„é›†åˆ.
- [Protein LM](https://github.com/google-research/google-research/tree/master/protein_lm) - ä¸ºè›‹ç™½è´¨å®æ–½ BERT å’Œè‡ªå›å½’æ¨¡å‹ï¼Œå¦‚ä¸­æ‰€è¿° [_Biological Structure å’Œ Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences_](https://www.biorxiv.org/content/10.1101/622803v1.full) å’Œ [_ProGen: Language Modeling for Protein Generation_](https://www.biorxiv.org/content/10.1101/2020.03.07.982272v2).
- [Slot Attention](https://github.com/google-research/google-research/tree/master/ptopk_patch_selection) - å‚è€ƒå®æ–½ [_Differentiable Patch Selection for Image Recognition_](https://arxiv.org/abs/2104.03059).
- [Vision Transformer](https://github.com/google-research/vision_transformer) - æ­£å¼å®æ–½ [_An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale_](https://arxiv.org/abs/2010.11929).
- [FID computation](https://github.com/matthias-wright/jax-fid) - æ¸¯å£ [mseitzer/pytorch-fid](https://github.com/mseitzer/pytorch-fid) åˆ°äºšéº».
- [ARDM](https://github.com/google-research/google-research/tree/master/autoregressive_diffusion) - æ­£å¼å®æ–½ [_Autoregressive Diffusion Models_](https://arxiv.org/abs/2110.02037).
- [D3PM](https://github.com/google-research/google-research/tree/master/d3pm) - æ­£å¼å®æ–½ [_Structured Denoising Diffusion Models in Discrete State-Spaces_](https://arxiv.org/abs/2107.03006).
- [Gumbel-max Causal Mechanisms](https://github.com/google-research/google-research/tree/master/gumbel_max_causal_gadgets) - ä»£ç  [_Learning Generalized Gumbel-max Causal Mechanisms_](https://arxiv.org/abs/2111.06888), æœ‰é¢å¤–çš„ä»£ç  [GuyLor/gumbel_max_causal_gadgets_part2](https://github.com/GuyLor/gumbel_max_causal_gadgets_part2).
- [Latent Programmer](https://github.com/google-research/google-research/tree/master/latent_programmer) - ICML 2021 è®ºæ–‡ä»£ç  [_Latent Programmer: Discrete Latent Codes for Program Synthesis_](https://arxiv.org/abs/2012.00377).
- [SNeRG](https://github.com/google-research/google-research/tree/master/snerg) - æ­£å¼å®æ–½ [_Baking Neural Radiance Fields for Real-Time View Synthesis_](https://phog.github.io/snerg).
- [Spin-weighted Spherical CNNs](https://github.com/google-research/google-research/tree/master/spin_spherical_cnns) - æ”¹ç¼– [_Spin-Weighted Spherical CNNs_](https://arxiv.org/abs/2006.10731).
- [VDVAE](https://github.com/google-research/google-research/tree/master/vdvae_flax) - æ”¹ç¼– [_Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images_](https://arxiv.org/abs/2011.10650), åŸå§‹ä»£ç åœ¨ [openai/vdvae](https://github.com/openai/vdvae).
- [MUSIQ](https://github.com/google-research/google-research/tree/master/musiq) - ICCV 2021 è®ºæ–‡çš„æ£€æŸ¥ç‚¹å’Œæ¨¡å‹æ¨ç†ä»£ç  [_MUSIQ: Multi-scale Image Quality Transformer_](https://arxiv.org/abs/2108.05997)
- [AQuaDem](https://github.com/google-research/google-research/tree/master/aquadem) - æ­£å¼å®æ–½ [_Continuous Control with Action Quantization from Demonstrations_](https://arxiv.org/abs/2110.10149).
- [Combiner](https://github.com/google-research/google-research/tree/master/combiner) - æ­£å¼å®æ–½ [_Combiner: Full Attention Transformer with Sparse Computation Cost_](https://arxiv.org/abs/2107.05768).
- [Dreamfields](https://github.com/google-research/google-research/tree/master/dreamfields) - ICLR 2022 è®ºæ–‡çš„æ­£å¼å®æ–½ [_Progressive Distillation for Fast Sampling of Diffusion Models_](https://ajayj.com/dreamfields).
- [GIFT](https://github.com/google-research/google-research/tree/master/gift) - æ­£å¼å®æ–½ [_Gradual Domain Adaptation in the Wild:When Intermediate Distributions are Absent_](https://arxiv.org/abs/2106.06080).
- [Light Field Neural Rendering](https://github.com/google-research/google-research/tree/master/light_field_neural_rendering) - æ­£å¼å®æ–½ [_Light Field Neural Rendering_](https://arxiv.org/abs/2112.09687).
- [Sharpened Cosine Similarity in JAX by Raphael Pisoni](https://colab.research.google.com/drive/1KUKFEMneQMS3OzPYnWZGkEnry3PdzCfn?usp=sharing) - é”åŒ–ä½™å¼¦ç›¸ä¼¼åº¦å±‚çš„ JAX/Flax å®ç°.

### Haiku

- [AlphaFold](https://github.com/deepmind/alphafold) - AlphaFold v2.0 æ¨ç†ç®¡é“çš„å®ç°ï¼Œåœ¨ [_Highly accurate protein structure prediction with AlphaFold_](https://www.nature.com/articles/s41586-021-03819-2).
- [Adversarial Robustness](https://github.com/deepmind/deepmind-research/tree/master/adversarial_robustness) - å‚è€ƒä»£ç  [_Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples_](https://arxiv.org/abs/2010.03593) å’Œ [_Fixing Data Augmentation to Improve Adversarial Robustness_](https://arxiv.org/abs/2103.01946).
- [Bootstrap Your Own Latent](https://github.com/deepmind/deepmind-research/tree/master/byol) - è®ºæ–‡çš„å®æ–½ [_Bootstrap your own latent: A new approach to self-supervised Learning_](https://arxiv.org/abs/2006.07733).
- [Gated Linear Networks](https://github.com/deepmind/deepmind-research/tree/master/gated_linear_networks) - GLN æ˜¯ä¸€ä¸ªæ— åå‘ä¼ æ’­ç¥ç»ç½‘ç»œå®¶æ—.
- [Glassy Dynamics](https://github.com/deepmind/deepmind-research/tree/master/glassy_dynamics) - è®ºæ–‡çš„å¼€æºå®ç° [_Unveiling the predictive power of static structure in glassy systems_](https://www.nature.com/articles/s41567-020-0842-8).
- [MMV](https://github.com/deepmind/deepmind-research/tree/master/mmv) - ä¸­æ¨¡å‹çš„ä»£ç  [_Self-Supervised MultiModal Versatile Networks_](https://arxiv.org/abs/2006.16228).
- [Normalizer-Free Networks](https://github.com/deepmind/deepmind-research/tree/master/nfnets) - å®˜æ–¹ä¿³å¥å®æ–½ [_NFNets_](https://arxiv.org/abs/2102.06171).
- [NuX](https://github.com/Information-Fusion-Lab-Umass/NuX) - ä½¿ç”¨ JAX è§„èŒƒåŒ–æµç¨‹.
- [OGB-LSC](https://github.com/deepmind/deepmind-research/tree/master/ogb_lsc) - æ­¤å­˜å‚¨åº“åŒ…å« DeepMind çš„æ¡ç›® [PCQM4M-LSC](https://ogb.stanford.edu/kddcup2021/pcqm4m/) ï¼ˆé‡å­åŒ–å­¦ï¼‰å’Œ [MAG240M-LSC](https://ogb.stanford.edu/kddcup2021/mag240m/) ï¼ˆå­¦æœ¯å›¾ï¼‰
çš„è½¨é“ [OGB Large-Scale Challenge](https://ogb.stanford.edu/kddcup2021/) ï¼ˆOGB-LSCï¼‰.
- [Persistent Evolution Strategies](https://github.com/google-research/google-research/tree/master/persistent_es) - ç”¨äºè®ºæ–‡çš„ä»£ç  [_Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies_](http://proceedings.mlr.press/v139/vicol21a.html).
- [Two Player Auction Learning](https://github.com/degregat/two-player-auctions) - JAX æ‰§è¡Œæ–‡ä»¶ [_Auction learning as a two-player game_](https://arxiv.org/abs/2006.05684).
- [WikiGraphs](https://github.com/deepmind/deepmind-research/tree/master/wikigraphs) - é‡ç°ç»“æœçš„åŸºçº¿ä»£ç  [_WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Datase_](https://aclanthology.org/2021.textgraphs-1.7).

### Trax

- [Reformer](https://github.com/google/trax/tree/master/trax/models/reformer) - Reformerï¼ˆé«˜æ•ˆå˜å‹å™¨ï¼‰æ¶æ„çš„å®æ–½.

### NumPyro

- [lqg](https://github.com/RothkopfLab/lqg) - è®ºæ–‡ä¸­çº¿æ€§äºŒæ¬¡é«˜æ–¯é—®é¢˜çš„è´å¶æ–¯é€†æœ€ä¼˜æ§åˆ¶çš„å®˜æ–¹å®ç° [_Putting perception into action with inverse optimal control for continuous psychophysics_](https://elifesciences.org/articles/76635)


<a name="videos" />

## Videos

- [NeurIPS 2020: JAX Ecosystem Meetup](https://www.youtube.com/watch?v=iDxJxIyzSiM) - JAXï¼Œå®ƒåœ¨ DeepMind çš„ä½¿ç”¨ï¼Œä»¥åŠå·¥ç¨‹å¸ˆã€ç§‘å­¦å®¶å’Œ JAX æ ¸å¿ƒå›¢é˜Ÿä¹‹é—´çš„è®¨è®º.
- [Introduction to JAX](https://youtu.be/0mVmRHMaOJ4) - JAX ä¸­ä»é›¶å¼€å§‹çš„ç®€å•ç¥ç»ç½‘ç»œ.
- [JAX: Accelerated Machine Learning Research | SciPy 2020 | VanderPlas](https://youtu.be/z-WSrQDXkuM) - JAX çš„æ ¸å¿ƒè®¾è®¡ï¼Œå®ƒå¦‚ä½•æ¨åŠ¨æ–°ç ”ç©¶ï¼Œä»¥åŠå¦‚ä½•å¼€å§‹ä½¿ç”¨å®ƒ.
- [Bayesian Programming with JAX + NumPyro â€” Andy Kitchen](https://youtu.be/CecuWGpoztw) - ä½¿ç”¨ NumPyro çš„è´å¶æ–¯å»ºæ¨¡ç®€ä»‹.
- [JAX: Accelerated machine-learning research via composable function transformations in Python | NeurIPS 2019 | Skye Wanderman-Milne](https://slideslive.com/38923687/jax-accelerated-machinelearning-research-via-composable-function-transformations-in-python) - JAX ä»‹ç»ä»‹ç» [_Program Transformations for Machine Learning_](https://program-transformations.github.io) ä½œåŠ.
- [JAX on Cloud TPUs | NeurIPS 2020 | Skye Wanderman-Milne and James Bradbury](https://drive.google.com/file/d/1jKxefZT1xJDUxMman6qrQVed7vWI0MIn/edit) - é€šè¿‡æ¼”ç¤ºå±•ç¤º TPU ä¸»æœºè®¿é—®.
- [Deep Implicit Layers - Neural ODEs, Deep Equilibirum Models, and Beyond | NeurIPS 2020](https://slideslive.com/38935810/deep-implicit-layers-neural-odes-equilibrium-models-and-beyond) - Zico Kolterã€David Duvenaud å’Œ Matt Johnson ä½¿ç”¨ Colab ç¬”è®°æœ¬åˆ›å»ºçš„æ•™ç¨‹å¯åœ¨ [_Deep Implicit Layers_](http://implicit-layers-tutorial.org).
- [Solving y=mx+b with Jax on a TPU Pod slice - Mat Kelcey](http://matpalm.com/blog/ymxb_pod_slice/) - ä¸€ä¸ªåŒ…å« Colab ç¬”è®°æœ¬çš„å››éƒ¨åˆ† YouTube æ•™ç¨‹ç³»åˆ—ï¼Œä» Jax åŸºç¡€çŸ¥è¯†å¼€å§‹ï¼Œç„¶ååœ¨ v3-32 TPU Pod slice ä¸Šä½¿ç”¨æ•°æ®å¹¶è¡Œæ–¹æ³•è¿›è¡Œè®­ç»ƒ.
- [JAX, Flax & Transformers ğŸ¤—](https://github.com/huggingface/transformers/blob/9160d81c98854df44b1d543ce5d65a6aa28444a2/examples/research_projects/jax-projects/README.md#talks) - å›´ç»• JAX / Flaxã€å˜å½¢é‡‘åˆšã€å¤§è§„æ¨¡è¯­è¨€å»ºæ¨¡å’Œå…¶ä»–é‡è¦ä¸»é¢˜è¿›è¡Œä¸ºæœŸ 3 å¤©çš„è®¨è®º.

<a name="papers" />

## Papers

æœ¬éƒ¨åˆ†åŒ…å«ä¸“æ³¨äº JAX çš„è®ºæ–‡ï¼ˆä¾‹å¦‚åŸºäº JAX çš„åº“ç™½çš®ä¹¦ã€JAX ç ”ç©¶ç­‰ï¼‰. åœ¨ JAX ä¸­å®ç°çš„è®ºæ–‡åˆ—åœ¨ [Models/Projects](#projects) éƒ¨åˆ†.

<!--lint ignore awesome-list-item-->
- [__Compiling machine learning programs via high-level tracing__. Roy Frostig, Matthew James Johnson, Chris Leary. _MLSys 2018_.](https://mlsys.org/Conferences/doc/2018/146.pdf) - æè¿° JAX æ—©æœŸç‰ˆæœ¬çš„ç™½çš®ä¹¦ï¼Œè¯¦ç»†è¯´æ˜å¦‚ä½•è·Ÿè¸ªå’Œç¼–è¯‘è®¡ç®—.
- [__JAX, M.D.: A Framework for Differentiable Physics__. Samuel S. Schoenholz, Ekin D. Cubuk. _NeurIPS 2020_.](https://arxiv.org/abs/1912.04232) - å¼•å…¥ JAX, MDï¼Œè¿™æ˜¯ä¸€ä¸ªå¯åŒºåˆ†çš„ç‰©ç†åº“ï¼Œå…¶ä¸­åŒ…æ‹¬æ¨¡æ‹Ÿç¯å¢ƒã€äº¤äº’åŠ¿ã€ç¥ç»ç½‘ç»œç­‰.
- [__Enabling Fast Differentially Private SGD via Just-in-Time Compilation and Vectorization__. Pranav Subramani, Nicholas Vadivelu, Gautam Kamath. _arXiv 2020_.](https://arxiv.org/abs/2010.09063) - ä½¿ç”¨ JAX çš„ JIT å’Œ VMAP å®ç°æ¯”ç°æœ‰åº“æ›´å¿«çš„å·®å¼‚ç§æœ‰.
<!--lint enable awesome-list-item-->

<a name="tutorials-and-blog-posts" />

## Tutorials and Blog Posts

- [Using JAX to accelerate our research by David Budden and Matteo Hessel](https://deepmind.com/blog/article/using-jax-to-accelerate-our-research) - æè¿°äº† DeepMind çš„ JAX å’Œ JAX ç”Ÿæ€ç³»ç»Ÿçš„çŠ¶æ€.
- [Getting started with JAX (MLPs, CNNs & RNNs) by Robert Lange](https://roberttlange.github.io/posts/2020/03/blog-post-10/) - ä½¿ç”¨åŸºæœ¬çš„ JAX è¿ç®—ç¬¦ä»å¤´å¼€å§‹æ„å»ºç¥ç»ç½‘ç»œæ¨¡å—.
- [Tutorial: image classification with JAX and Flax Linen by 8bitmp3](https://github.com/8bitmp3/JAX-Flax-Tutorial-Image-Classification-with-Linen) - å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Flax çš„ Linen API åˆ›å»ºä¸€ä¸ªç®€å•çš„å·ç§¯ç½‘ç»œï¼Œå¹¶è®­ç»ƒå®ƒè¯†åˆ«æ‰‹å†™æ•°å­—.
- [Plugging Into JAX by Nick Doiron](https://medium.com/swlh/plugging-into-jax-16c120ec3302) - åœ¨ Kaggle èŠ±åˆ†ç±»æŒ‘æˆ˜ä¸­æ¯”è¾ƒ Flaxã€Haiku å’Œ Objax.
- [Meta-Learning in 50 Lines of JAX by Eric Jang](https://blog.evjang.com/2019/02/maml-jax.html) - JAX å’Œå…ƒå­¦ä¹ çš„ä»‹ç».
- [Normalizing Flows in 100 Lines of JAX by Eric Jang](https://blog.evjang.com/2019/07/nf-jax.html) - ç®€æ´çš„å®æ–½ [RealNVP](https://arxiv.org/abs/1605.08803).
- [Differentiable Path Tracing on the GPU/TPU by Eric Jang](https://blog.evjang.com/2019/11/jaxpt.html) - å®æ–½è·¯å¾„è¿½è¸ªæ•™ç¨‹.
- [Ensemble networks by Mat Kelcey](http://matpalm.com/blog/ensemble_nets) - é›†æˆç½‘ç»œæ˜¯ä¸€ç§å°†æ¨¡å‹é›†æˆè¡¨ç¤ºä¸ºå•ä¸ªé€»è¾‘æ¨¡å‹çš„æ–¹æ³•.
- [Out of distribution (OOD) detection by Mat Kelcey](http://matpalm.com/blog/ood_using_focal_loss) - å®æ–½ä¸åŒçš„ OOD æ£€æµ‹æ–¹æ³•.
- [Understanding Autodiff with JAX by Srihari Radhakrishna](https://www.radx.in/jax.html) - äº†è§£ autodiff å¦‚ä½•ä½¿ç”¨ JAX å·¥ä½œ.
- [From PyTorch to JAX: towards neural net frameworks that purify stateful code by Sabrina J. Mielke](https://sjmielke.com/jax-purify.htm) - å±•ç¤ºå¦‚ä½•ä»ç±»ä¼¼ PyTorch çš„ç¼–ç é£æ ¼è½¬å˜ä¸ºæ›´å‡½æ•°å¼çš„ç¼–ç é£æ ¼.
- [Extending JAX with custom C++ and CUDA code by Dan Foreman-Mackey](https://github.com/dfm/extending-jax) - æ¼”ç¤ºåœ¨ JAX ä¸­æä¾›è‡ªå®šä¹‰æ“ä½œæ‰€éœ€çš„åŸºç¡€ç»“æ„çš„æ•™ç¨‹.
- [Evolving Neural Networks in JAX by Robert Tjarko Lange](https://roberttlange.github.io/posts/2021/02/cma-es-jax/) - æ¢ç´¢ JAX å¦‚ä½•ä¸ºä¸‹ä¸€ä»£å¯æ‰©å±•çš„ç¥ç»è¿›åŒ–ç®—æ³•æä¾›åŠ¨åŠ›.
- [Exploring hyperparameter meta-loss landscapes with JAX by Luke Metz](http://lukemetz.com/exploring-hyperparameter-meta-loss-landscapes-with-jax/) - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ JAX é€šè¿‡ SGD å’Œ Momentum æ‰§è¡Œå†…éƒ¨æŸå¤±ä¼˜åŒ–ã€ä½¿ç”¨æ¢¯åº¦è¿›è¡Œå¤–éƒ¨æŸå¤±ä¼˜åŒ–ä»¥åŠä½¿ç”¨è¿›åŒ–ç­–ç•¥è¿›è¡Œå¤–éƒ¨æŸå¤±ä¼˜åŒ–.
- [Deterministic ADVI in JAX by Martin Ingram](https://martiningram.github.io/deterministic-advi/) - æ¼”ç»ƒä½¿ç”¨ JAX è½»æ¾å¹²å‡€åœ°å®ç°è‡ªåŠ¨å¾®åˆ†å˜åˆ†æ¨ç† (ADVI).
- [Evolved channel selection by Mat Kelcey](http://matpalm.com/blog/evolved_channel_selection/) - è®­ç»ƒå¯¹ä¸åŒåˆ†è¾¨ç‡çš„è¾“å…¥é€šé“çš„ä¸åŒç»„åˆå…·æœ‰é²æ£’æ€§çš„åˆ†ç±»æ¨¡å‹ï¼Œç„¶åä½¿ç”¨é—ä¼ ç®—æ³•æ¥å†³å®šç‰¹å®šæŸå¤±çš„æœ€ä½³ç»„åˆ.
- [Introduction to JAX by Kevin Murphy](https://colab.research.google.com/github/probml/probml-notebooks/blob/main/notebooks/jax_intro.ipynb) - Colabï¼Œä»‹ç»è¯­è¨€çš„å„ä¸ªæ–¹é¢å¹¶å°†å®ƒä»¬åº”ç”¨äºç®€å•çš„ ML é—®é¢˜.
- [Writing an MCMC sampler in JAX by Jeremie Coullon](https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/) - å…³äºåœ¨ JAX ä¸­ç¼–å†™ MCMC é‡‡æ ·å™¨çš„ä¸åŒæ–¹æ³•ä»¥åŠé€Ÿåº¦åŸºå‡†çš„æ•™ç¨‹.
- [How to add a progress bar to JAX scans and loops by Jeremie Coullon](https://www.jeremiecoullon.com/2021/01/29/jax_progress_bar/) - å…³äºå¦‚ä½•ä½¿ç”¨â€œhost_callbackâ€æ¨¡å—å‘ JAX ä¸­çš„å·²ç¼–è¯‘å¾ªç¯æ·»åŠ è¿›åº¦æ¡çš„æ•™ç¨‹.
- [Get started with JAX by Aleksa GordiÄ‡](https://github.com/gordicaleksa/get-started-with-JAX) - ä»é›¶ JAX çŸ¥è¯†åˆ°åœ¨ Haiku ä¸­æ„å»ºç¥ç»ç½‘ç»œçš„ä¸€ç³»åˆ—ç¬”è®°æœ¬å’Œè§†é¢‘.
- [Writing a Training Loop in JAX + FLAX by Saurav Maheshkar and Soumik Rakshit](https://wandb.ai/jax-series/simple-training-loop/reports/Writing-a-Training-Loop-in-JAX-FLAX--VmlldzoyMzA4ODEy) - å…³äºåœ¨ JAXã€Flax å’Œ Optax ä¸­ç¼–å†™ç®€å•çš„ç«¯åˆ°ç«¯åŸ¹è®­å’Œè¯„ä¼°ç®¡é“çš„æ•™ç¨‹.
- [Implementing NeRF in JAX by Soumik Rakshit and Saurav Maheshkar](https://wandb.ai/wandb/nerf-jax/reports/Implementing-NeRF-in-JAX--VmlldzoxODA2NDk2?galleryTag=jax) - JAX ä¸­ç”±ç¥ç»è¾å°„åœºè¡¨ç¤ºçš„åœºæ™¯çš„ 3D ä½“ç§¯æ¸²æŸ“æ•™ç¨‹.
- [Deep Learning tutorials with JAX+Flax by Phillip Lippe](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.html) - ä¸€ç³»åˆ—è§£é‡Šå„ç§æ·±åº¦å­¦ä¹ æ¦‚å¿µçš„ç¬”è®°æœ¬ï¼Œä»åŸºç¡€çŸ¥è¯†ï¼ˆä¾‹å¦‚ JAX/Flax ä»‹ç»ã€æ¿€æ´»å‡½æ•°ï¼‰åˆ°æœ€æ–°è¿›å±•ï¼ˆä¾‹å¦‚ Vision Transformersã€SimCLRï¼‰ï¼Œä»¥åŠ PyTorch çš„ç¿»è¯‘.

<a name="books" />

## Books

- [Jax in Action](https://www.manning.com/books/jax-in-action) - å°† JAX ç”¨äºæ·±åº¦å­¦ä¹ å’Œå…¶ä»–æ•°å­¦å¯†é›†å‹åº”ç”¨ç¨‹åºçš„å®è·µæŒ‡å—.

<a name="community" />

## Community

- [JAX GitHub Discussions](https://github.com/google/jax/discussions)
- [Reddit](https://www.reddit.com/r/JAX/)

## Contributing

æ¬¢è¿æŠ•ç¨¿ï¼ é˜…è¯» [contribution guidelines](https://github.com/n2cholas/awesome-jax/blob/master/contributing.md) ç¬¬ä¸€çš„.
